{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV and Resume Parsing with Custom NER Training with SpaCy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "YwoUrU9iBP4a",
        "outputId": "9f5f581d-3a7f-429f-8777-9595d510caf6"
      },
      "source": [
        "import spacy\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-91160b3c63dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fitz'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aNyEddQRZx3",
        "outputId": "79d94612-39c8-4047-f3af-8554247d6b7b"
      },
      "source": [
        "!pip install PyMuPDF"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.18.16-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 12.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy3bN7YbRb0S"
      },
      "source": [
        "import sys, fitz"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfmcY6XALPQa",
        "outputId": "99d69470-828e-40d2-c37d-af6baec9f336"
      },
      "source": [
        "!git clone https://github.com/laxmimerit/Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 34 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kv3eLusNkGA"
      },
      "source": [
        "train_data = pickle.load(open('/content/Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python/train_data.pkl', 'rb'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0VtCrqIPIMJ",
        "outputId": "f2adff39-81ce-4628-e6b1-c4131acc7fd2"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [(1749, 1755, 'Companies worked at'),\n",
              "   (1696, 1702, 'Companies worked at'),\n",
              "   (1417, 1423, 'Companies worked at'),\n",
              "   (1356, 1793, 'Skills'),\n",
              "   (1209, 1215, 'Companies worked at'),\n",
              "   (1136, 1248, 'Skills'),\n",
              "   (928, 932, 'Graduation Year'),\n",
              "   (858, 889, 'College Name'),\n",
              "   (821, 856, 'Degree'),\n",
              "   (787, 791, 'Graduation Year'),\n",
              "   (744, 750, 'Companies worked at'),\n",
              "   (722, 742, 'Designation'),\n",
              "   (658, 664, 'Companies worked at'),\n",
              "   (640, 656, 'Designation'),\n",
              "   (574, 580, 'Companies worked at'),\n",
              "   (555, 573, 'Designation'),\n",
              "   (470, 493, 'Companies worked at'),\n",
              "   (444, 469, 'Designation'),\n",
              "   (308, 314, 'Companies worked at'),\n",
              "   (234, 240, 'Companies worked at'),\n",
              "   (175, 198, 'Companies worked at'),\n",
              "   (93, 137, 'Email Address'),\n",
              "   (39, 48, 'Location'),\n",
              "   (13, 38, 'Designation'),\n",
              "   (0, 12, 'Name')]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSNm7gkFPKiw"
      },
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "def train_model(train_data):\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last = True)\n",
        "    \n",
        "    for _, annotation in train_data:\n",
        "        for ent in annotation['entities']:\n",
        "            ner.add_label(ent[2])\n",
        "            \n",
        "    \n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(10):\n",
        "            print(\"Statring iteration \" + str(itn))\n",
        "            random.shuffle(train_data)\n",
        "            losses = {}\n",
        "            index = 0\n",
        "            for text, annotations in train_data:\n",
        "                try:\n",
        "                    nlp.update(\n",
        "                        [text],  # batch of texts\n",
        "                        [annotations],  # batch of annotations\n",
        "                        drop=0.2,  # dropout - make it harder to memorise data\n",
        "                        sgd=optimizer,  # callable to update weights\n",
        "                        losses=losses)\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "                \n",
        "            print(losses)  \n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEDUZ3MIPakB",
        "outputId": "0aa4cfa2-63e5-4de9-93f4-486c97fbabd9"
      },
      "source": [
        "train_model(train_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statring iteration 0\n",
            "{'ner': 16025.374306274563}\n",
            "Statring iteration 1\n",
            "{'ner': 6970.50497810004}\n",
            "Statring iteration 2\n",
            "{'ner': 8099.69608098048}\n",
            "Statring iteration 3\n",
            "{'ner': 5354.330367719865}\n",
            "Statring iteration 4\n",
            "{'ner': 7095.667677543774}\n",
            "Statring iteration 5\n",
            "{'ner': 5895.383440774901}\n",
            "Statring iteration 6\n",
            "{'ner': 5307.975516742968}\n",
            "Statring iteration 7\n",
            "{'ner': 4103.556920135014}\n",
            "Statring iteration 8\n",
            "{'ner': 4421.364590935201}\n",
            "Statring iteration 9\n",
            "{'ner': 4553.19716159358}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwAgAr9CPciB"
      },
      "source": [
        "nlp.to_disk('nlp_model')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXYqyl7PPea5"
      },
      "source": [
        "nlp_model = spacy.load('nlp_model')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "qIXtSRvNPfWg",
        "outputId": "3e028396-ff03-484f-ebe6-3c9594160c1e"
      },
      "source": [
        "train_data[0][0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Rahul Bollu Software Engineer - Disney  Hyderabad, Telangana - Email me on Indeed: indeed.com/r/Rahul-Bollu/dc40f5ce78045741  • Over 3.5 years of experience in implementing organization DevOps strategy in various environments of Linux and windows servers along with adopting cloud strategies based on Amazon Web Services. • Experience in Cloud Technologies like Amazon Web Services (AWS) VPC, EC2, S3, ELB, IAM, Auto Scaling, Route 53, SQS, SNS, RDS, Cloud Watch, Dynamo DB. • Utilized Cloud Watch to monitor AWS resources to set alarms for notification, and to monitor logs for a better operation of the system. • Experience working with automated build platforms/continuous integration using DevOps architecture. • Implementing DevOps tools like Ansible as configuration management for Continuous Integration and Continuous Deployment with build tools using Maven on Cloud Infrastructure using AWS. • Experience on version control tool GIT- Creating branches, tracking changes, maintaining the history of code and helping the Developers in GIT related issues. • Worked on Jenkins for continuous integration and for End to End automation for all build and deployments. • Worked with Ansible as a configuration management tool, created playbooks to automate repetitive tasks, quickly deploy applications, and proactively manage change. • Knowledge on Docker.  WORK EXPERIENCE  Software Engineer  Disney -  September 2014 to Present  Responsibilities: * Coordinate/assist developers with establishing and applying appropriate branching, labeling/ naming conventions using GIT source control. * Implemented the setup for Master slave architecture to improve the performance of Jenkins. * Used Jenkins to implement Continuous Integration and deployment into Tomcat/Web logic Application server. * Created Ansible playbooks for automating the Infrastructure, deployment process. * Managed clients, roles, tasks, playbooks in Ansible. * Deploy and monitor scalable infrastructure on AWS & configuration management. * Worked on making application more scalable and highly available in AWS. * Created AWS IAM roles & total architecture deployment end to end (creation of EC2 instances & its infrastructure)  Environment: GIT, Maven, Jenkins, Tomcat, Docker, Jira, AWS, Ansible, LAMP  Software Engineer  https://www.indeed.com/r/Rahul-Bollu/dc40f5ce78045741?isid=rex-download&ikw=download-top&co=IN   HCL Technologies -  September 2014 to Present  〓 Coordinate/assist developers with establishing and applying appropriate branching, labeling/ naming conventions using GIT source control. 〓 Implemented the setup for Master slave architecture to improve the performance of Jenkins. 〓 Used Jenkins to implement Continuous Integration and deployment into Tomcat/Web logic Application server. 〓 Created Ansible playbooks for automating the Infrastructure, deployment process. 〓 Managed clients, roles, tasks, playbooks in Ansible. 〓 Deploy and monitor scalable infrastructure on AWS & configuration management. 〓 Worked on making application more scalable and highly available in AWS. 〓 Created AWS IAM roles & total architecture deployment end to end (creation of EC2 instances & its infrastructure).  Process Associate  Microsoft -  July 2013 to August 2014  Responsibilities: * Collect and document user requirements. * Design and develop database architecture for information systems projects. * Design, construct, modify, integrate, implement and test data models and database management systems. * Conduct research and provide advice to other informatics professionals regarding the selection, application and implementation of database management tools. * Operate database management systems to analyze data and perform data mining analysis.  EDUCATION  Bachelor Of Science  Vaughn College of Aeronautics and Technology  SKILLS  AWS (3 years), Tomcat, Ansible, git, LAMP, docker, jenkins, Maven, Jira  ADDITIONAL INFORMATION  Technical Skills:  Cloud Technologies: AWS  Operating Systems: Linux, Windows. Version Control Systems: GIT Automated Build Tools: Maven Continuous Integration: Jenkins    Scripting Languages: Shell Scripting Configuration Management: Ansible. Container service: Docker'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJrhWJF2Ph5p",
        "outputId": "aff0903b-3ae9-4760-89e8-34ab68aaf677"
      },
      "source": [
        "doc = nlp_model(train_data[0][0])\n",
        "for ent in doc.ents:\n",
        "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME                          - Rahul Bollu\n",
            "DESIGNATION                   - Software Engineer\n",
            "LOCATION                      - Hyderabad\n",
            "DESIGNATION                   - Software Engineer\n",
            "DESIGNATION                   - Software Engineer\n",
            "COMPANIES WORKED AT           - Microsoft\n",
            "DEGREE                        - Bachelor Of Science\n",
            "COLLEGE NAME                  - Vaughn College of Aeronautics and Technology\n",
            "SKILLS                        - AWS (3 years), Tomcat, Ansible, git, LAMP, docker, jenkins, Maven, Jira  ADDITIONAL INFORMATION  Technical Skills:  Cloud Technologies: AWS  Operating Systems: Linux, Windows. Version Control Systems: GIT Automated Build Tools: Maven Continuous Integration: Jenkins    Scripting Languages: Shell Scripting Configuration Management: Ansible. Container service: Docker\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNnHOuADPkXZ",
        "outputId": "232df5ee-5df9-456e-cae1-213a35cd74e5"
      },
      "source": [
        "fname = '/content/Resume-and-CV-Summarization-and-Parsing-with-Spacy-in-Python/Alice Clark CV.pdf'\n",
        "doc = fitz.open(fname)\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text = text + str(page.getText())\n",
        "\n",
        "tx = \" \".join(text.split('\\n'))\n",
        "print(tx)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alice Clark  AI / Machine Learning    Delhi, India Email me on Indeed  •  20+ years of experience in data handling, design, and development  •  Data Warehouse: Data analysis, star/snow flake scema data modelling and design specific to  data warehousing and business intelligence  •  Database: Experience in database designing, scalability, back-up and recovery, writing and  optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.  Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure,  Stream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake  analytics(U-SQL)  Willing to relocate anywhere    WORK EXPERIENCE  Software Engineer  Microsoft – Bangalore, Karnataka  January 2000 to Present  1. Microsoft Rewards Live dashboards:  Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping  online. Microsoft Rewards members can earn points when searching with Bing, browsing with  Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft  Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft  rewards website. Rewards live dashboards gives a live picture of usage world-wide and by  markets like US, Canada, Australia, new user registration count, top/bottom performing rewards  offers, orders stats and weekly trends of user activities, orders and new user registrations. the  PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.  Technology/Tools used    EDUCATION  Indian Institute of Technology – Mumbai  2001    SKILLS  Machine Learning, Natural Language Processing, and Big Data Handling    ADDITIONAL INFORMATION  Professional Skills  • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal  skills with ability to interact with individuals at all the levels  • Quick learner and maintains cordial relationship with project manager and team members and  good performer both in team and independent job environments  • Positive attitude towards superiors &amp; peers  • Supervised junior developers throughout project lifecycle and provided technical assistance  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKqXbmspRg3S",
        "outputId": "280d8a56-ded4-4763-f0b1-d1f89ff468f9"
      },
      "source": [
        "doc = nlp_model(tx)\n",
        "for ent in doc.ents:\n",
        "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAME                          - Alice Clark\n",
            "DESIGNATION                   - AI / Machine Learning\n",
            "COMPANIES WORKED AT           - Microsoft – Bangalore, Karnataka  January 2000 to Present  1. Microsoft Rewards Live dashboards:  Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping  online. Microsoft Rewards members can earn points when searching with Bing, browsing with  Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft  Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft  rewards website. Rewards live dashboards gives a live picture of usage world-wide and by  markets like US, Canada, Australia, new user registration count, top/bottom performing rewards  offers, orders stats and weekly trends of user activities, orders and new user registrations. the  PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.  Technology/Tools used    EDUCATION  Indian Institute of Technology – Mumbai  2001    SKILLS  Machine Learning, Natural Language Processing, and Big Data Handling    ADDITIONAL INFORMATION  Professional Skills  • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal  skills with ability to interact with individuals at all the levels  • Quick learner and maintains cordial relationship with project manager and team members and  good performer both in team and independent job environments  • Positive attitude towards superiors &amp; peers  • Supervised junior developers throughout project lifecycle and provided technical assistance  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWdfjm6zRjVy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}